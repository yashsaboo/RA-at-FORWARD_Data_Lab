{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import All Dependencies\n",
    "# import cv2, os, bz2, json, csv, difflib, requests, socket, whois, urllib.request, urllib.parse, urllib.error, re, OpenSSL, ssl\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from urllib.parse import urlparse\n",
    "from urllib.request import Request, urlopen\n",
    "# from selenium import webdriver\n",
    "from matplotlib import pyplot as plt\n",
    "from bs4 import BeautifulSoup\n",
    "# from timeout import timeout\n",
    "import requests\n",
    "import numpy as np\n",
    "import urllib\n",
    "import cv2\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.desired_capabilities import DesiredCapabilities\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import time\n",
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "import io\n",
    "from difflib import SequenceMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib \n",
    "  \n",
    "try: \n",
    "    from urllib.parse import urlencode           \n",
    "except ImportError: \n",
    "    from urllib import urlencode \n",
    "try: \n",
    "    from urllib.request import urlopen \n",
    "except ImportError: \n",
    "    from urllib2 import urlopen \n",
    "\n",
    "import sys "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TinyURL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Taken from https://www.geeksforgeeks.org/python-url-shortener-using-tinyurl-api/\n",
    "#Returns the url subtracting the domain name with www and com stuff\n",
    "#So, http://tinyurl.com/y5bffkh2 ---becomes---> y5bffkh2\n",
    "def getTinyURL(URL): \n",
    "    request_url = ('http://tinyurl.com/api-create.php?' + urlencode({'url':URL}))     \n",
    "    with contextlib.closing(urlopen(request_url)) as response:                       \n",
    "        return response.read().decode('utf-8 ')[19:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns Beautiful Soup object\n",
    "def getHTML(URL):\n",
    "    try:\n",
    "        hdr = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.157 Safari/537.36'} #Make the user agent verified, that is Mozilla\n",
    "#         req = Request(URL,headers=hdr)\n",
    "        req = requests.get(URL, headers=hdr)\n",
    "        page = req.text #Get URL HTML contents\n",
    "        soup = BeautifulSoup(page, 'html.parser') #Convert to BeutifulSoup\n",
    "        print(\"Built Soup\")\n",
    "        #prettyText = str(soup.prettify()) #Convert the HTML in its form\n",
    "        return soup\n",
    "    except Exception as e:\n",
    "# #         if e.__class__.__name__ == \"TimeoutError\": raise TimeoutError(\"\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://selenium-python.readthedocs.io/locating-elements.html#locating-by-xpath\n",
    "#XPath can either id or name relative\n",
    "def getMyXPath(currentTag): #Original XPath\n",
    "    returnXPath = \"\"\n",
    "    while(currentTag.parent!=None):\n",
    "        if \"id\" in (currentTag.attrs):\n",
    "            print(\"true\")\n",
    "            returnXPath = currentTag.name + \"[@id='\" + currentTag.attrs['id'].strip() + \"']/\" + returnXPath #//form[@id='loginForm']\n",
    "            break\n",
    "        if \"name\" in (currentTag.attrs):\n",
    "            print(\"true\")\n",
    "            returnXPath = currentTag.name + \"[@name='\" + currentTag.attrs['name'].strip() + \"']/\" + returnXPath #//form[@id='loginForm']\n",
    "            break \n",
    "        returnXPath = currentTag.name + \"/\" + returnXPath\n",
    "        currentTag = currentTag.parent\n",
    "        print(currentTag.attrs)\n",
    "        \n",
    "        \n",
    "    returnXPath = returnXPath.replace(\"[document]/html\",\"/\") #When it reaches the end of document parent, it adds the following it it's start, so we need to delete it\n",
    "#     if not returnXPath.startswith(\"//\"): #the XPath should start with 2 forward slash\n",
    "#         returnXPath = \"//\" + returnXPath\n",
    "    if not returnXPath.startswith(\"/\"): #the XPath should start with 1 forward slash: Update\n",
    "        returnXPath = \"/\" + returnXPath\n",
    "    if returnXPath.endswith(\"/\"): #the XPath should not end with forward slash\n",
    "        returnXPath = returnXPath[:-1]\n",
    "    \n",
    "    returnXPath = returnXPath.replace(\"meta/\",\"\").replace(\"table/tr\", \"table/tbody/tr\") #Few changes to be made while performing XPath\n",
    "    return (returnXPath) #//div[@id='tab-panel-0-w3']/div/span/h2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def getStackXPath(element): #XPath code from Stack Overflow\n",
    "    \"\"\"\n",
    "    Generate xpath of soup element\n",
    "    :param element: bs4 text or node\n",
    "    :return: xpath as string\n",
    "    \"\"\"\n",
    "    components = []\n",
    "    child = element if element.name else element.parent\n",
    "    for parent in child.parents:\n",
    "        \"\"\"\n",
    "        @type parent: bs4.element.Tag\n",
    "        \"\"\"\n",
    "        previous = itertools.islice(parent.children, 0, parent.contents.index(child))\n",
    "        xpath_tag = child.name\n",
    "        xpath_index = sum(1 for i in previous if i.name == xpath_tag) + 1\n",
    "        components.append(xpath_tag if xpath_index == 1 else '%s[%d]' % (xpath_tag, xpath_index))\n",
    "        child = parent\n",
    "    components.reverse()\n",
    "    return '/%s' % '/'.join(components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMyStackXPath(element): #My XPath code modified with Stack Overflow's one\n",
    "    \"\"\"\n",
    "    Generate xpath of soup element\n",
    "    :param element: bs4 text or node\n",
    "    :return: xpath as string\n",
    "    \"\"\"\n",
    "    components = []\n",
    "    child = element if element.name else element.parent\n",
    "    for parent in child.parents:\n",
    "        \"\"\"\n",
    "        @type parent: bs4.element.Tag\n",
    "        \"\"\"\n",
    "        \n",
    "        if \"id\" in (child.attrs):\n",
    "            print(\"true\")\n",
    "            components.append(child.name + \"[@id='\" + child.attrs['id'].strip() + \"']\")    #//form[@id='loginForm']\n",
    "            break\n",
    "        if \"name\" in (child.attrs):\n",
    "            print(\"true\")\n",
    "            components.append(child.name + \"[@name='\" + child.attrs['name'].strip() + \"']\") #//form[@id='loginForm']\n",
    "            break \n",
    "        \n",
    "        previous = itertools.islice(parent.children, 0, parent.contents.index(child))\n",
    "        xpath_tag = child.name\n",
    "        xpath_index = sum(1 for i in previous if i.name == xpath_tag) + 1\n",
    "        components.append(xpath_tag if xpath_index == 1 else '%s[%d]' % (xpath_tag, xpath_index))\n",
    "        print(\"xpath_tag:\",xpath_tag)\n",
    "        print(\"xpath_tag.attrs:\",child.attrs)\n",
    "        print(\"xpath_index:\",xpath_index)\n",
    "        print(\"components:\",components)\n",
    "        child = parent\n",
    "    components.reverse()\n",
    "    return '/%s' % '/'.join(components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTheTagElementForPrice(gShopPriceUpdated, soup):\n",
    "    returnPriceElementTag = None\n",
    "    try:\n",
    "        dummyVar = soup(text=re.compile(gShopPriceUpdated))\n",
    "    #     print(dummyVar)\n",
    "        for elem in dummyVar:\n",
    "#             print(\"elem.parent\",elem.parent)\n",
    "#             print(\"elem.parent.name\",elem.parent.name)\n",
    "            if returnPriceElementTag == None: #The first element is the return value unless we encounter a heading tag\n",
    "                returnPriceElementTag = elem.parent\n",
    "            if \"h\" in elem.parent.name: #Found the heading tag, so return this tag and break the loop\n",
    "                returnPriceElementTag = elem.parent\n",
    "                return returnPriceElementTag\n",
    "            if \"span\" in elem.parent.name: #Found the span tag, so return this tag and break the loop\n",
    "                returnPriceElementTag = elem.parent\n",
    "                return returnPriceElementTag\n",
    "    except Exception as e:\n",
    "        print(\"Error in getTheTagElementForPrice(gShopPriceUpdated, soup)\")\n",
    "    return returnPriceElementTag\n",
    "\n",
    "def findPriceElementTag(gShopPrice, soup): #gShopPrice = $379.00\n",
    "    gShopPrice = gShopPrice.replace(\"now\",\"\").strip() #GShop soemtimes gives prices with now suffix like \"$0.00 now\"\n",
    "    print(gShopPrice)\n",
    "    \n",
    "    if \"$\" in gShopPrice:\n",
    "        gShopPriceUpdated = gShopPrice.replace(\"$\", \"\\$\") #gShopPriceUpdated = \\$379.00; Required because $ is reserved keyword for regex\n",
    "        print(gShopPriceUpdated)\n",
    "        returnPriceElementTag = getTheTagElementForPrice(gShopPriceUpdated, soup)\n",
    "        if returnPriceElementTag != None and len(str(returnPriceElementTag))<400:\n",
    "            return returnPriceElementTag\n",
    "    \n",
    "    gShopPriceUpdated = gShopPrice.replace(\"$\",\"\") #gShopPriceUpdated = 379.00\n",
    "    print(gShopPriceUpdated)\n",
    "    returnPriceElementTag = getTheTagElementForPrice(gShopPriceUpdated, soup)\n",
    "    if returnPriceElementTag != None and len(str(returnPriceElementTag))<400:\n",
    "        return returnPriceElementTag\n",
    "        \n",
    "    gShopPriceUpdated = gShopPrice.replace(\"$\", \"\\$\").split(\".\")[0] #gShopPriceUpdated = \\$379\n",
    "    print(gShopPriceUpdated)\n",
    "    returnPriceElementTag = getTheTagElementForPrice(gShopPriceUpdated, soup)\n",
    "    if returnPriceElementTag != None and len(str(returnPriceElementTag))<400:\n",
    "        return returnPriceElementTag\n",
    "        \n",
    "    gShopPriceUpdated = gShopPrice.replace(\"$\",\"\").split(\".\")[0] #gShopPriceUpdated = 379\n",
    "    print(gShopPriceUpdated)\n",
    "    returnPriceElementTag = getTheTagElementForPrice(gShopPriceUpdated, soup)\n",
    "    if returnPriceElementTag != None and len(str(returnPriceElementTag))<400:\n",
    "        return returnPriceElementTag\n",
    "        \n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit Testing for XPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.walmart.com/ip/Farberware-3-2-Quart-Digital-Oil-Less-Fryer-White/264698854?athcpid=264698854&athpgid=athenaHomepage&athcgid=null&athznid=BestInDeals&athieid=v1&athstid=CS020&athguid=466001f5-46cfa622-5eb821569a18a716&athancid=null&athena=true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "priceOfCurrentScreenshot = \"39\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = getHTML(URL)\n",
    "# returnPriceElementTag = findPriceElementTag(priceOfCurrentScreenshot, soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getMyStackXPath(returnPriceElementTag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
